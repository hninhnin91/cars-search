{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Environment Setup**\n",
        "\n"
      ],
      "metadata": {
        "id": "Wxr1D2FD9suC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9o_0qjajzt3"
      },
      "source": [
        "!pip install transformers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwbsv0aTu7Kw"
      },
      "source": [
        "pip install sentence_transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9t-Eq9XxR0Z"
      },
      "source": [
        "!pip install gensim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbHTN2Yqxa4O"
      },
      "source": [
        "!pip install --upgrade gensim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkcGPYo6tuZ3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk import sent_tokenize\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords list\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import gensim.downloader as api\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import TfidfModel\n",
        "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
        "from gensim.similarities import SparseTermSimilarityMatrix\n",
        "from gensim.similarities import SoftCosineSimilarity\n",
        "\n",
        "from re import sub\n",
        "from gensim.utils import simple_preprocess\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdKGfpzeD0-o"
      },
      "source": [
        "#Similarity search for car make model\n",
        "\n",
        "The current problem of the existing search engine is the less accurate search results from users’ inputs that might affect customer experiences. For example, when a user types ‘cc’ in the search box, the returned result is usually Honda Accord at the top, instead of Volkswagen cc.\n",
        "\n",
        "Especially while you type the model, mostly getting the results is not accurate.\n",
        "\n",
        "I hope AI will help us the problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khcj2PkBEMgM"
      },
      "source": [
        "mount the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-w1Vkzqj4LV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d7f7e6-d1f5-400d-e53f-ed867e470690"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5RP2K0Tj3dP"
      },
      "source": [
        "df=pd.read_csv('/content/gdrive/MyDrive/data/car_make model_2.csv')\n",
        "#df=pd.read_csv('/content/new_carmodel2 - new_carmodel2.csv')\n",
        "df['CarModel']=df['CarModel'].astype(str)\n",
        "df['CarModel']= df['CarModel'].apply(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "UzeRaNZ2XytF",
        "outputId": "dfa39f31-af48-49d1-9c48-741bb55f5497"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CarModel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>audi q3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chevrolet malibu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cadillac escalade esv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chevrolet corvette</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>acura rlx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>rivian r1t</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>toyota rav4 prime</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1261</th>\n",
              "      <td>volkswagen atlas cross sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1262</th>\n",
              "      <td>gmc hummer ev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>jeep grand wagoneer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1264 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          CarModel\n",
              "0                          audi q3\n",
              "1                 chevrolet malibu\n",
              "2            cadillac escalade esv\n",
              "3               chevrolet corvette\n",
              "4                        acura rlx\n",
              "...                            ...\n",
              "1259                    rivian r1t\n",
              "1260             toyota rav4 prime\n",
              "1261  volkswagen atlas cross sport\n",
              "1262                 gmc hummer ev\n",
              "1263           jeep grand wagoneer\n",
              "\n",
              "[1264 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKQdJuBjkimH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c176863a-dacc-4b72-b6a7-3e05b9a777c4"
      },
      "source": [
        "df['CarModel']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                            audi q3\n",
              "1                   chevrolet malibu\n",
              "2              cadillac escalade esv\n",
              "3                 chevrolet corvette\n",
              "4                          acura rlx\n",
              "                    ...             \n",
              "1259                      rivian r1t\n",
              "1260               toyota rav4 prime\n",
              "1261    volkswagen atlas cross sport\n",
              "1262                   gmc hummer ev\n",
              "1263             jeep grand wagoneer\n",
              "Name: CarModel, Length: 1264, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1kQeLamwSgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c72d1870-f1cb-4af0-d1ff-c63b18fe6056"
      },
      "source": [
        "df['CarModel'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1264,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-xcakk6EcJI"
      },
      "source": [
        "corpus = df['CarModel'].astype(str).values.tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lu7kBGNFgpd"
      },
      "source": [
        "#put the search terms, and corpus\n",
        "base_document = corpus\n",
        "#query = 'cc'\n",
        "query = 'bmw'\n",
        "\n",
        "#threhold\n",
        "highest_score = 1\n",
        "lowest_score = 0.55\n",
        "\n",
        "#top result\n",
        "top_k = 5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUcjJUS0vJmK"
      },
      "source": [
        "import operator\n",
        "from itertools import islice\n",
        "\n",
        "\n",
        "def get_best_similar(best_suit):\n",
        "  sorted_d = dict( sorted(best_suit.items(), key=operator.itemgetter(1),reverse=True))\n",
        "  return (dict(islice(sorted_d.items(), top_k)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya85uPsFFM_x"
      },
      "source": [
        "\n",
        "## **BERT**\n",
        "\n",
        "We came out with solution to solve this issue is using BERT pre-train model.\n",
        "\n",
        "What is BERT?\n",
        "\n",
        "**BERT** (introduced in [this paper](https://arxiv.org/abs/1810.04805)) stands for Bidirectional Encoder Representations from Transformers. It is a trained Transformer Encoder stack. BERT is a model that broke several records for how well models can handle language-based tasks after the release paper. It is saving the time, energy, knowledge, and resources that would have gone to training a language-processing model from scratch. Its the good point.\n",
        "\n",
        "The paper presents two model sizes for BERT:\n",
        "BERT BASE (L=12, H=768, A=12, Total Parameters=110M) and BERT LARGE (L=24, H=1024, A=16, Total Parameters=340M).In this project, i will use bert-base.\n",
        "\n",
        "\n",
        "more clear explaination in [it](https://jalammar.github.io/illustrated-bert/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05kIwEfhj7UP"
      },
      "source": [
        "#def cosine_similarities_test(query_embedding, corpus_embeddings, top_k=5):\n",
        "#\tcos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "#\ttop_results = torch.topk(cos_scores, k=top_k)\n",
        "#\tfor score, idx in zip(top_results[0], top_results[1]):\n",
        "#\t\tprint(corpus[idx], \"(Score: {:.4f})\".format(score))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKtvr6W4j_zl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b9e7fab-d582-4e20-9c48-b4e805205c77"
      },
      "source": [
        "def get_bert_similarity(query, base_document):\n",
        "\t# This will download and load the pretrained model offered by UKPLab.\n",
        "\tmodel = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "\t# Although it is not explicitly stated in the official document of sentence transformer, the original BERT is meant for a shorter sentence.\n",
        "\t#We will feed the model by sentences instead of the whole documents.\n",
        "\tbase_embeddings_sentences = model.encode(base_document)\n",
        "\tfor document in [query]:\n",
        "\t\tembeddings_sentences = model.encode(document)\n",
        "\t\tcos_scores = util.pytorch_cos_sim(embeddings_sentences, base_embeddings_sentences)[0]\n",
        "\t\ttop_results = torch.topk(cos_scores, k=top_k)\n",
        "\t\tprint(\"\\n\\n======================\\n\\n\")\n",
        "\t\tprint(\"Query:\", document)\n",
        "\t\tprint(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "\t\tfor score, idx in zip(top_results[0], top_results[1]):\n",
        "\t\t\tif score >= 0.5:\n",
        "\t\t\t\tprint(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
        "\t\t\t#if lowest_score <= score and highest_score >= score:\n",
        "\t\t\t#\tmost_similar_document = corpus[idx]\n",
        "\t\t\t\t#print(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
        "\n",
        "\t\t#cosine_similarities_test(embeddings_sentences, base_embeddings_sentences, top_k=5)\n",
        "\t\t#hits = util.semantic_search(embeddings_sentences, base_embeddings_sentences, top_k=5)\n",
        "\t\t#print(hits)\n",
        "\t\t#hits = hits[0]      #Get the hits for the first query\n",
        "\t\t#for hit in hits:\n",
        "\t\t#\tprint(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
        "\n",
        "print(\"BERT approach:\")\n",
        "get_bert_similarity(query, base_document)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT approach:\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: bmw\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "bmw m3 (Score: 0.8521)\n",
            "bmw m (Score: 0.8281)\n",
            "bmw i8 (Score: 0.8146)\n",
            "bmw z8 (Score: 0.8105)\n",
            "bmw z3 (Score: 0.8067)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2fZ8EAiFOrQ"
      },
      "source": [
        "## **TF-idf (stands for term frequency-inverse document frequency)**\n",
        "\n",
        "I have performed another approach which is TF-idf\n",
        "\n",
        "what is [TF-idf](http://www.tfidf.com/) ?\n",
        "\n",
        "TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:\n",
        "\n",
        "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
        "\n",
        "IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:\n",
        "\n",
        "IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
        "\n",
        "Example:\n",
        "\n",
        "Consider a document containing 100 words wherein the word cat appears 3 times. The term frequency (i.e., tf) for cat is then (3 / 100) = 0.03. Now, assume we have 10 million documents and the word cat appears in one thousand of these. Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 / 1,000) = 4. Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYy9gHymAdUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a0243c-38f4-4aa3-f7aa-d42d9bc97806"
      },
      "source": [
        "def get_simple_Tfidf_similarity(search_terms, documents):\n",
        "\tbest_suit = {}\n",
        "\tdoc_vectors = TfidfVectorizer().fit_transform([search_terms] + documents)\n",
        "\n",
        "\tcosine_similarities = linear_kernel(doc_vectors[0:1], doc_vectors).flatten()\n",
        "\tdocument_scores = [item.item() for item in cosine_similarities[1:]]\n",
        "\n",
        "\thighest_score_index = 0\n",
        "\t#count = 0\n",
        "\tfor i, score in enumerate(document_scores):\n",
        "\t\t#if count == 5:\n",
        "\t\t#\tbreak\n",
        "\n",
        "\t\tif lowest_score <= score and highest_score >= score:\n",
        "\t\t\t#count = count +1\n",
        "\t\t\thighest_score_index = i\n",
        "\t\t\tmost_similar_document = documents[highest_score_index]\n",
        "\t\t\tbest_suit[most_similar_document] = \tscore\n",
        "\t\t\t#print(\"Most similar document by TF-IDF with the score: \",most_similar_document, \" (Score: {:.4f})\".format(score))\n",
        "\treturn best_suit\n",
        "\n",
        "print(\"TF-idf approach:\")\n",
        "\n",
        "print(\"\\n\\n======================\\n\\n\")\n",
        "print(\"Query:\", query)\n",
        "\n",
        "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "\n",
        "best_suit = get_simple_Tfidf_similarity(query, base_document)\n",
        "\n",
        "for key, value in get_best_similar(best_suit).items():\n",
        "  print(\"Most similar document by TF-IDF with the score: \",key, \" (Score: {:.4f})\".format(value))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-idf approach:\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: bmw\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "Most similar document by TF-IDF with the score:  bmw m  (Score: 1.0000)\n",
            "Most similar document by TF-IDF with the score:  bmw 3 series  (Score: 0.6760)\n",
            "Most similar document by TF-IDF with the score:  bmw 7 series  (Score: 0.6760)\n",
            "Most similar document by TF-IDF with the score:  bmw 4 series  (Score: 0.6760)\n",
            "Most similar document by TF-IDF with the score:  bmw 2 series  (Score: 0.6760)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3ctCUczfvm-"
      },
      "source": [
        "by lemmatizer approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glXMs8abJUeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52051d9-0925-4eb4-d864-b6666b098ca0"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Interface lemma tokenizer from nltk with sklearn\n",
        "class LemmaTokenizer:\n",
        "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`']\n",
        "    def __init__(self):\n",
        "        self.wnl = WordNetLemmatizer()\n",
        "    def __call__(self, doc):\n",
        "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]\n",
        "\n",
        "# Lemmatize the stop words\n",
        "tokenizer=LemmaTokenizer()\n",
        "token_stop = tokenizer(' '.join(stop_words))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_lemma_Tfidf_similarity(search_terms, documents):\n",
        "\tbest_suit = {}\n",
        "\n",
        "\t# Create TF-idf model\n",
        "\tvectorizer = TfidfVectorizer(stop_words=token_stop,tokenizer=tokenizer)\n",
        "\n",
        "\tdoc_vectors = vectorizer.fit_transform([search_terms] + documents)\n",
        "\n",
        "\t# Calculate similarity\n",
        "\tcosine_similarities = linear_kernel(doc_vectors[0:1], doc_vectors).flatten()\n",
        "\tdocument_scores = [item.item() for item in cosine_similarities[1:]]\n",
        "\n",
        "\t#print(document_scores)\n",
        "\thighest_score_index = 0\n",
        "\tfor i, score in enumerate(document_scores):\n",
        "\t\tif lowest_score <= score and highest_score >= score:\n",
        "\t\t\thighest_score_index = i\n",
        "\t\t\tmost_similar_document = documents[highest_score_index]\n",
        "\t\t\tbest_suit[most_similar_document] = \tscore\n",
        "\t\t\t#print(\"Most similar document by TF-IDF with the score: \",most_similar_document, \" (Score: {:.4f})\".format(score))\n",
        "\treturn best_suit\n",
        "\n",
        "print(\"TF-idf approach:\")\n",
        "\n",
        "print(\"\\n\\n======================\\n\\n\")\n",
        "print(\"Query:\", query)\n",
        "\n",
        "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "\n",
        "best_suit = get_lemma_Tfidf_similarity(query, base_document)\n",
        "\n",
        "for key, value in get_best_similar(best_suit).items():\n",
        "  print(\"Most similar document by TF-IDF with the score: \",key, \" (Score: {:.4f})\".format(value))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-idf approach:\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: bmw\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "Most similar document by TF-IDF with the score:  bmw m  (Score: 1.0000)\n",
            "Most similar document by TF-IDF with the score:  bmw x5  (Score: 0.5532)\n",
            "Most similar document by TF-IDF with the score:  bmw x6 m  (Score: 0.5532)\n",
            "Most similar document by TF-IDF with the score:  bmw x6  (Score: 0.5532)\n",
            "Most similar document by TF-IDF with the score:  bmw z4  (Score: 0.5532)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVQW_PmeF10x"
      },
      "source": [
        "\n",
        "## **GloVe**\n",
        "\n",
        "\n",
        "GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\n",
        "\n",
        "it maps words into numerical vectors — points in a multi-dimensional space so that words that occur together often are near each other in space. It is an unsupervised learning algorithm, developed at Stanford University in 2014. [more details](https://nlp.stanford.edu/projects/glove/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcQpuCmK0D5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc43206d-311a-4ea0-b29c-c3b2997d9b7a"
      },
      "source": [
        "\n",
        "stopwords = ['the', 'and', 'are', 'a']\n",
        "\n",
        "def preprocess(doc):\n",
        "    # Tokenize, clean up input document string\n",
        "    doc = sub(r'<img[^<>]+(>|$)', \" image_token \", doc)\n",
        "    doc = sub(r'<[^<>]+(>|$)', \" \", doc)\n",
        "    doc = sub(r'\\[img_assist[^]]*?\\]', \" \", doc)\n",
        "    doc = sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', \" url_token \", doc)\n",
        "    return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stopwords]\n",
        "\n",
        "def get_glove_similarity(query_string, documents):\n",
        "\tbest_suit = {}\n",
        "\t# Preprocess the documents, including the query string\n",
        "\tcorpus = [preprocess(document) for document in documents]\n",
        "\tquery = preprocess(query_string)\n",
        "\n",
        "\tglove = api.load(\"glove-wiki-gigaword-50\")\n",
        "\tsimilarity_index = WordEmbeddingSimilarityIndex(glove)\n",
        "\n",
        "\t# Build the term dictionary, TF-idf model\n",
        "\tdictionary = Dictionary(corpus+[query])\n",
        "\ttfidf = TfidfModel(dictionary=dictionary)\n",
        "\n",
        "\t# Create the term similarity matrix.\n",
        "\tsimilarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf)\n",
        "\n",
        "\t# Compute Soft Cosine Measure between the query and the documents.\n",
        "\tquery_tf = tfidf[dictionary.doc2bow(query)]\n",
        "\n",
        "\tindex = SoftCosineSimilarity(\n",
        "\t\t\t\ttfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
        "\t\t\t\tsimilarity_matrix)\n",
        "\n",
        "\tdoc_similarity_scores = index[query_tf]\n",
        "\tprint(doc_similarity_scores)\n",
        "\t# Output the sorted similarity scores and documents\n",
        "\tsorted_indexes = np.argsort(doc_similarity_scores)[::-1]\n",
        "\tfor idx in sorted_indexes:\n",
        "\t\tif lowest_score <= doc_similarity_scores[idx] and highest_score >= doc_similarity_scores[idx]:\n",
        "\t\t\thighest_score_index = idx\n",
        "\t\t\tmost_similar_document = documents[highest_score_index]\n",
        "\t\t\tbest_suit[most_similar_document] = \tdoc_similarity_scores[idx]\n",
        "\n",
        "\treturn best_suit\n",
        "\n",
        "best_suit = get_glove_similarity(query, base_document)\n",
        "#print(sorted_indexes)\n",
        "\n",
        "for key, value in get_best_similar(best_suit).items():\n",
        "  print(\"Most similar document by golve with the score: \",key, \" (Score: {:.4f})\".format(value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 752/752 [00:15<00:00, 48.56it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/termsim.py:382: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  normalized_corpus = np.multiply(corpus, 1.0 / corpus_norm)\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/termsim.py:382: RuntimeWarning: invalid value encountered in multiply\n",
            "  normalized_corpus = np.multiply(corpus, 1.0 / corpus_norm)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.69495046 0.39313257 0.         ... 0.69939244 0.         0.        ]\n",
            "Most similar document by golve with the score:  bmw m  (Score: 1.0000)\n",
            "Most similar document by golve with the score:  bmw x3  (Score: 1.0000)\n",
            "Most similar document by golve with the score:  bmw 7 series  (Score: 1.0000)\n",
            "Most similar document by golve with the score:  bmw m5  (Score: 1.0000)\n",
            "Most similar document by golve with the score:  bmw 2 series  (Score: 1.0000)\n"
          ]
        }
      ]
    }
  ]
}